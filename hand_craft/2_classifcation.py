# -*- coding: utf-8 -*-
"""
Created on Thu Apr 22 11:55:32 2021

@author: xiatong

load csv and test the performance

"""


import numpy as np
import pandas as pd
from sklearn import decomposition, metrics, preprocessing
from sklearn.svm import SVC
# from xgboost import XGBClassifier


def get_metrics(probs, label):
    predicted = []
    for i in range(len(probs)):
        if probs[i] > 0.5:
            predicted.append(1)
        else:
            predicted.append(0)

    auc = metrics.roc_auc_score(label, probs)
    TN, FP, FN, TP = metrics.confusion_matrix(label, predicted).ravel()
    # Sensitivity, hit rate, recall, or true positive rate
    TPR = TP * 1.0 / (TP + FN)
    # Specificity or true negative rate
    TNR = TN * 1.0 / (TN + FP)

    return auc, TPR, TNR


def get_CI(data, AUC, Sen, Spe):
    AUCs = []
    TPRs = []
    TNRs = []
    for s in range(1000):
        np.random.seed(s)  # Para2
        sample = np.random.choice(range(len(data)), len(data), replace=True)
        samples = [data[i] for i in sample]
        sample_pro = [x[0] for x in samples]
        sample_label = [x[1] for x in samples]
        try:
            get_metrics(sample_pro, sample_label)
        except ValueError:
            np.random.seed(1001)  # Para2
            sample = np.random.choice(range(len(data)), len(data), replace=True)
            samples = [data[i] for i in sample]
            sample_pro = [x[0] for x in samples]
            sample_label = [x[1] for x in samples]
        else:
            auc, TPR, TNR = get_metrics(sample_pro, sample_label)
        AUCs.append(auc)
        TPRs.append(TPR)
        TNRs.append(TNR)

    q_0 = pd.DataFrame(np.array(AUCs)).quantile(0.025)[0]  # 2.5% percentile
    q_1 = pd.DataFrame(np.array(AUCs)).quantile(0.975)[0]  # 97.5% percentile

    q_2 = pd.DataFrame(np.array(TPRs)).quantile(0.025)[0]  # 2.5% percentile
    q_3 = pd.DataFrame(np.array(TPRs)).quantile(0.975)[0]  # 97.5% percentile

    q_4 = pd.DataFrame(np.array(TNRs)).quantile(0.025)[0]  # 2.5% percentile
    q_5 = pd.DataFrame(np.array(TNRs)).quantile(0.975)[0]  # 97.5% percentile

    print(
        str(AUC.round(4))
        + "("
        + str(q_0.round(4))
        + "-"
        + str(q_1.round(4))
        + ")"
        + "&"
        + str(Sen.round(4))
        + "("
        + str(q_2.round(4))
        + "-"
        + str(q_3.round(4))
        + ")"
        "&" + str(Spe.round(4)) + "(" + str(q_4.round(4)) + "-" + str(q_5.round(4)) + ")"
    )


inputFile = "features_988_delay_960.csv"
df_features = pd.read_csv(inputFile)
df_cough = df_features["cough_feature"].map(lambda x: np.array([float(v) for v in x.split(";")]))
cough = np.array([x for x in df_cough])[:,:988]

'''cough_energy = np.concatenate([cough[:,:248],cough[:, 4131:4223], cough[:,5488:5548]],axis=1)
cough_spectral = np.concatenate([cough[:,248:1519], cough[:,1953:3224], cough[:,4223:5166], cough[:,5548:6163]], axis=1)
cough_cepstral = np.concatenate([cough[:,1519:1953], cough[:,3224:3658], cough[:,5166:5488], cough[:,6163:6373]], axis=1)
cough_voicing = cough[:, 3658:4131]
   '''                           
# cough = np.concatenate([np.array([x for x in df_cough])[:, :12] , np.array([x for x in df_cough])[:, 156:192]], axis=1) 
cough_delay = np.array([x for x in df_cough])[:, -36:]
#np.random.shuffle(cough_delay)

df_breath = df_features["breath_feature"].map(lambda x: np.array([float(v) for v in x.split(";")]))
# print(df_breath)
breath = np.array([x for x in df_breath])[:, :988]

'''breath_energy = np.concatenate([breath[:,:248],breath[:, 4131:4223], breath[:,5488:5548]],axis=1)
breath_spectral = np.concatenate([breath[:,248:1519], breath[:,1953:3224], breath[:,4223:5166], breath[:,5548:6163]], axis=1)
breath_cepstral = np.concatenate([breath[:,1519:1953], breath[:,3224:3658], breath[:,5166:5488], breath[:,6163:6373]], axis=1)
breath_voicing = breath[:, 3658:4131]
    '''                          
breath_delay = np.array([x for x in df_breath])[:, -36:]
#np.random.shuffle(breath_delay)

df_voice = df_features["voice_feature"].map(lambda x: np.array([float(v) for v in x.split(";")]))
voice = np.array([x for x in df_voice])[:, :988]

'''voice_energy = np.concatenate([voice[:,:248],voice[:, 4131:4223], voice[:,5488:5548]],axis=1)
voice_spectral = np.concatenate([voice[:,248:1519], voice[:,1953:3224], voice[:,4223:5166], voice[:,5548:6163]], axis=1)
voice_cepstral = np.concatenate([voice[:,1519:1953], voice[:,3224:3658], voice[:,5166:5488], voice[:,6163:6373]], axis=1)
voice_voicing = voice[:, 3658:4131]
       '''                     

# voice = np.concatenate([np.array([x for x in df_voice])[:, :12], np.array([x for x in df_voice])[:, 156:192]], axis=1)
voice_delay = np.array([x for x in df_voice])[:, -36:]
#np.random.shuffle(voice_delay)


x_data = np.concatenate([cough,breath, voice], axis=1)
x_data_delay = np.concatenate([cough, cough_delay, breath, breath_delay ,voice, voice_delay], axis=1)
x_data_voice = voice
x_data_delay_voice = np.concatenate([voice, voice_delay], axis=1)
x_data_cough = cough
x_data_delay_cough = np.concatenate([cough, cough_delay], axis=1)
x_data_breath = breath
x_data_delay_breath = np.concatenate([breath, breath_delay], axis=1)


'''x_data_energy = np.concatenate([cough_energy, breath_energy, voice_energy], axis=1)
x_data_delay_energy = np.concatenate([cough_energy, cough_delay, breath_energy, breath_delay, voice_energy, voice_delay], axis=1)
x_data_spectral = np.concatenate([cough_spectral, breath_spectral, voice_spectral], axis=1)
x_data_delay_spectral = np.concatenate([cough_spectral, cough_delay, breath_spectral, breath_delay, voice_spectral, voice_delay], axis=1)
x_data_cepstral = np.concatenate([cough_cepstral, breath_cepstral, voice_cepstral], axis=1)
x_data_delay_cepstral = np.concatenate([cough_cepstral, cough_delay, breath_cepstral, breath_delay, voice_cepstral, voice_delay], axis=1)
x_data_voicing = np.concatenate([cough_voicing, breath_voicing, voice_voicing], axis=1)
x_data_delay_voicing = np.concatenate([cough_voicing, cough_delay, breath_voicing, breath_delay, voice_voicing, voice_delay], axis=1)

x_data_energy_cough = cough_energy
x_data_delay_energy_cough = np.concatenate([cough_energy, cough_delay], axis=1)
x_data_spectral_cough = cough_spectral
x_data_delay_spectral_cough = np.concatenate([cough_spectral, cough_delay], axis=1)
x_data_cepstral_cough = cough_cepstral
x_data_delay_cepstral_cough = np.concatenate([cough_cepstral, cough_delay], axis=1)
x_data_voicing_cough = cough_voicing
x_data_delay_voicing_cough = np.concatenate([cough_voicing, cough_delay], axis=1)

x_data_energy_breath = breath_energy
x_data_delay_energy_breath = np.concatenate([breath_energy, breath_delay], axis=1)
x_data_spectral_breath = breath_spectral
x_data_delay_spectral_breath = np.concatenate([breath_spectral, breath_delay], axis=1)
x_data_cepstral_breath = breath_cepstral
x_data_delay_cepstral_breath = np.concatenate([breath_cepstral, breath_delay], axis=1)
x_data_voicing_breath = breath_voicing
x_data_delay_voicing_breath = np.concatenate([breath_voicing, breath_delay], axis=1)

x_data_energy_voice = voice_energy
x_data_delay_energy_voice = np.concatenate([voice_energy, voice_delay], axis=1)
x_data_spectral_voice = voice_spectral
x_data_delay_spectral_voice = np.concatenate([voice_spectral, voice_delay], axis=1)
x_data_cepstral_voice = voice_cepstral
x_data_delay_cepstral_voice = np.concatenate([voice_cepstral, voice_delay], axis=1)
x_data_voicing_voice = voice_voicing
x_data_delay_voicing_voice = np.concatenate([voice_voicing, voice_delay], axis=1)

x_delay = np.concatenate([cough_delay, breath_delay, voice_delay], axis=1)

x_data_delay_no_voicing = np.concatenate([x_data_energy, x_data_spectral, x_delay], axis=1)
'''
# np.random.shuffle(x_data_delay)
# print(cough.shape, breath.shape, voice.shape)
y_label = np.array(df_features["label"])
y_set = np.array(df_features["fold"])
AUCS = []
SENS = []
SPECS = []
for x_data in  [x_data_delay, x_data, x_data_delay_cough, x_data_cough, x_data_delay_breath, x_data_breath, x_data_delay_voice, x_data_voice]:

    x_data_train = x_data[y_set == 0]
    y_label_train = y_label[y_set == 0]
    x_data_vad = x_data[y_set == 1]
    y_label_vad = y_label[y_set == 1]
    x_data_test = x_data[y_set == 2]
    y_label_test = y_label[y_set == 2]

    # scale data
    scaler = preprocessing.StandardScaler().fit(x_data_train)
    x_train_n = scaler.transform(x_data_train)
    x_test_n = scaler.transform(x_data_test)
    x_vad_n = scaler.transform(x_data_vad)
    print(x_train_n.shape, x_test_n.shape, x_vad_n.shape)
    # use PCA to reduce the feature dimension
    pca = decomposition.PCA(0.9)
    pca.fit(x_train_n)
    x_train_n_pca = pca.fit_transform(x_train_n)
    x_test_n_pca = pca.transform(x_test_n)
    x_vad_n_pca = pca.transform(x_vad_n)

    print(x_train_n_pca.shape, x_test_n_pca.shape, x_vad_n_pca.shape)

    for c in [0.001]:
        print(c)
        clf = SVC(C=c, kernel="linear", gamma="auto", probability=True)
        # 
        #clf = XGBClassifier(learning_rate=0.1, n_estimators=1000,
                #max_depth=8, min_child_weight=1, gamma=0, subsample=0.8,
                #colsample_bytree=0.8, objective='binary:logistic',
                #nthread=8, scale_pos_weight=1, seed=0, tree_method='gpu_hist')

        clf = clf.fit(x_train_n_pca, y_label_train)

        predicted = clf.predict(x_vad_n_pca)
        probs = clf.predict_proba(x_vad_n_pca)
        auc = metrics.roc_auc_score(y_label_vad, probs[:, 1])
        precision, recall, _ = metrics.precision_recall_curve(y_label_vad, probs[:, 1])
        se = metrics.recall_score(y_label_vad, predicted, labels=[1], average=None)[0]
        sp = metrics.recall_score(y_label_vad, predicted, labels=[0], average=None)[0]
        print("auc", auc, "SE", se, "SP", sp)

        predicted = clf.predict(x_test_n_pca)
        probs = clf.predict_proba(x_test_n_pca)
        auc = metrics.roc_auc_score(y_label_test, probs[:, 1])
        precision, recall, _ = metrics.precision_recall_curve(y_label_test, probs[:, 1])
        se = metrics.recall_score(y_label_test, predicted, labels=[1], average=None)[0]
        sp = metrics.recall_score(y_label_test, predicted, labels=[0], average=None)[0]
        print("auc", auc, "SE", se, "SP", sp)

        data = [[probs[i, 1], y_label_test[i]] for i in range(len(y_label_test))]
        AUC, Sen, Spe = get_metrics(probs[:, 1], y_label_test)
        get_CI(data, AUC, Sen, Spe)
        AUCS.append(AUC)
        SENS.append(Sen)
        SPECS.append(Spe)
for i in range(len(AUCS)):
    if i % 2 == 0:
    
        AUC = AUCS[i]-AUCS[i+1]
        Sen = SENS[i]-SENS[i+1]
        Spe = SPECS[i]-SPECS[i+1]
        print(AUC, Sen, Spe)


# clf = SVC(C=0.001, kernel='linear',gamma='auto', probability=True)
# auc 0.7086871921345558 SE 0.6648501362397821 SP 0.6520681265206812
# auc 0.7108886021859103 SE 0.6505944517833554 SP 0.6679636835278858
# 0.71(0.69-0.73)&0.64(0.61-0.66)&0.68(0.66-0.7)

# #384
# 0.01
# auc 0.7240216259936223 SE 0.6444141689373297 SP 0.6727493917274939
# auc 0.7083999403749184 SE 0.6373844121532365 SP 0.6627756160830091
# 0.71(0.69-0.73)&0.63(0.6-0.65)&0.67(0.65-0.7)
# 0.05
# auc 0.7214692018536566 SE 0.6376021798365122 SP 0.6727493917274939
# auc 0.70406812679582 SE 0.6360634081902246 SP 0.6640726329442282
# 0.7(0.69-0.72)&0.62(0.6-0.65)&0.67(0.65-0.7)
# 0.001
# auc 0.7297562932171814 SE 0.6362397820163488 SP 0.6909975669099757
# auc 0.7253151305498016 SE 0.6433289299867899 SP 0.6867704280155642
# 0.73(0.71-0.74)&0.64(0.62-0.67)&0.69(0.66-0.71)
# 0.0001
# auc 0.7306463268296239 SE 0.6103542234332425 SP 0.7068126520681265
# auc 0.7279068083961708 SE 0.631439894319683 SP 0.704928664072633
# 0.73(0.71-0.74)&0.65(0.62-0.67)&0.69(0.67-0.71)


# 6373 features + delay
0.01
# auc 0.7508979876060177 SE 0.6581986143187067 SP 0.720173535791757
# auc 0.7376342113510073 SE 0.6845425867507886 SP 0.667705088265836
# 0.7376342113510073(0.72-0.76)&0.6487907465825447(0.62-0.68)&0.6978193146417445(0.67-0.73)
# 0.001
# auc 0.7667236101857093 SE 0.6720554272517321 SP 0.7527114967462039
# auc 0.7492484819499177 SE 0.6908517350157729 SP 0.6780893042575286
# 0.7492484819499177(0.73-0.77)&0.6624605678233438(0.63-0.69)&0.6915887850467289(0.66-0.72)
# 0.0001
# auc 0.7939663248385627 SE 0.6720554272517321 SP 0.7722342733188721
# auc 0.7728171580879502 SE 0.6992639327024185 SP 0.7279335410176532
# 0.7728171580879502(0.75-0.8)&0.6982124079915878(0.67-0.73)&0.7300103842159917(0.7-0.76)

# 6373 features
# 0.01
# auc 0.7562508453858217 SE 0.6628175519630485 SP 0.7310195227765727
# auc 0.7399791223754195 SE 0.6803364879074658 SP 0.6822429906542056
# 0.7399791223754195(0.72-0.76)&0.6414300736067298(0.61-0.67)&0.7144340602284528(0.68-0.74)
# 0.001
# auc 0.7716431294554963 SE 0.6720554272517321 SP 0.7505422993492408
# auc 0.7475718296202392 SE 0.6876971608832808 SP 0.6791277258566978
# 0.7475718296202392(0.73-0.77)&0.668769716088328(0.64-0.7)&0.6947040498442367(0.67-0.72)
# 0.0001
# auc 0.7959351344852289 SE 0.6674364896073903 SP 0.7787418655097614
# auc 0.7718775557892278 SE 0.694006309148265 SP 0.7206645898234684
# 0.7718775557892278(0.75-0.79)&0.6919032597266036(0.66-0.72)&0.7227414330218068(0.7-0.75)

# 6373 features + only power
# 0.0001
# auc 0.7956095043909966 SE 0.6697459584295612 SP 0.7744034707158352
# auc 0.7725605554845802 SE 0.6876971608832808 SP 0.7300103842159917
# 0.7725605554845802(0.75-0.79)&0.68664563617245(0.66-0.72)&0.7320872274143302(0.71-0.76)


# 384 features + delay
# 0.01
# auc 0.7793029512105925 SE 0.648960739030023 SP 0.7852494577006508
# auc 0.73041876452944 SE 0.6340694006309149 SP 0.7009345794392523
# 0.73041876452944(0.71-0.75)&0.619348054679285(0.59-0.65)&0.7102803738317757(0.68-0.74)
# 0.001
# auc 0.7814671389137983 SE 0.6327944572748267 SP 0.7765726681127982
# auc 0.7319518285938287 SE 0.6340694006309149 SP 0.6978193146417445
# 0.7319518285938287(0.71-0.75)&0.6309148264984227(0.6-0.66)&0.7019730010384216(0.67-0.73)
# 0.0001
# auc 0.7677731410278889 SE 0.6304849884526559 SP 0.7678958785249458
# auc 0.7230842977769479 SE 0.6130389064143007 SP 0.7040498442367601
# 0.7230842977769479(0.7-0.75)&0.6361724500525763(0.61-0.67)&0.6843198338525441(0.65-0.71)

# 384 features + only power
# 0.01
# auc 0.7824966309809481 SE 0.6397228637413395 SP 0.7874186550976139
# auc 0.7287917948314776 SE 0.637223974763407 SP 0.6998961578400831
# 0.7287917948314776(0.71-0.75)&0.6288117770767613(0.6-0.66)&0.711318795430945(0.68-0.74)
# 0.001
# auc 0.7835186085074619 SE 0.6327944572748267 SP 0.7809110629067245
# auc 0.7333172820215481 SE 0.637223974763407 SP 0.7092419522326064
# 0.7333172820215481(0.71-0.76)&0.6309148264984227(0.6-0.66)&0.7123572170301142(0.68-0.74)
# 0.0001
# auc 0.7686773907511033 SE 0.6166281755196305 SP 0.7700650759219089
# auc 0.7237585620645264 SE 0.5962145110410094 SP 0.7185877466251298
# 0.7237585620645264(0.7-0.75)&0.6246056782334385(0.59-0.65)&0.6905503634475597(0.66-0.72)

# 384 features
# 0.01
# auc 0.774388441634563 SE 0.6397228637413395 SP 0.7830802603036876
# auc 0.7197965086758978 SE 0.6203995793901157 SP 0.6884735202492211
# 0.7197965086758978(0.7-0.74)&0.6151419558359621(0.58-0.65)&0.7019730010384216(0.67-0.73)
# 0.001
# auc 0.7807006557689129 SE 0.6351039260969977 SP 0.7830802603036876
# auc 0.7251163720104431 SE 0.629863301787592 SP 0.6978193146417445
# 0.7251163720104431(0.7-0.75)&0.6235541535226078(0.59-0.65)&0.7030114226375909(0.67-0.73)
# 0.0001
# auc 0.7677631216403742 SE 0.6235565819861432 SP 0.7722342733188721
# auc 0.717741503996995 SE 0.594111461619348 SP 0.7019730010384216
# 0.717741503996995(0.69-0.74)&0.6161934805467929(0.59-0.64)&0.6812045690550363(0.65-0.71)

# 988 features + delay
# 0.01
# auc 0.7762320089372937 SE 0.628175519630485 SP 0.7830802603036876
# auc 0.7390935704123003 SE 0.6656151419558359 SP 0.6978193146417445
# 0.7390935704123003(0.72-0.76)&0.6498422712933754(0.62-0.68)&0.7071651090342679(0.68-0.74)
# 0.001
# auc 0.7787418655097614 SE 0.6327944572748267 SP 0.7809110629067245
# auc 0.7436671023451294 SE 0.6614090431125131 SP 0.7040498442367601
# 0.7436671023451294(0.72-0.77)&0.6572029442691903(0.63-0.69)&0.7092419522326064(0.68-0.74)
# 0.0001
# auc 0.7729481546793046 SE 0.6235565819861432 SP 0.7917570498915402
# auc 0.7421526010222611 SE 0.6403785488958991 SP 0.7341640706126688
# 0.7421526010222611(0.72-0.76)&0.655099894847529(0.63-0.69)&0.719626168224299(0.69-0.75)

# 988 features + only power
# 0.01
# auc 0.7712548781892963 SE 0.625866050808314 SP 0.7722342733188721
# auc 0.7357162433815637 SE 0.6666666666666666 SP 0.6978193146417445
# 0.7357162433815637(0.71-0.76)&0.6519453207150369(0.62-0.68)&0.7144340602284528(0.69-0.74)
# 0.001
# auc 0.7759690000150291 SE 0.6327944572748267 SP 0.7678958785249458
# auc 0.742527131630584 SE 0.6666666666666666 SP 0.7050882658359294
# 0.742527131630584(0.72-0.76)&0.6603575184016824(0.63-0.69)&0.7082035306334372(0.68-0.74)
# 0.0001
# auc 0.7715679840491351 SE 0.6235565819861432 SP 0.7874186550976139
# auc 0.7419118313454822 SE 0.6414300736067298 SP 0.7331256490134995
# 0.7419118313454822(0.72-0.76)&0.658254468980021(0.63-0.69)&0.7227414330218068(0.69-0.75)

# 988 features
# 0.01
# auc 0.7688727688076427 SE 0.6304849884526559 SP 0.7700650759219089
# auc 0.7318415440706783 SE 0.6519453207150369 SP 0.6936656282450675
# 0.7318415440706783(0.71-0.75)&0.6351209253417456(0.6-0.67)&0.7071651090342679(0.68-0.74)
# 0.001
# auc 0.7719988177122733 SE 0.6327944572748267 SP 0.7678958785249458
# auc 0.7387714522506232 SE 0.655099894847529 SP 0.6998961578400831
# 0.7387714522506232(0.72-0.76)&0.6456361724500526(0.62-0.68)&0.7071651090342679(0.68-0.74)
# 0.0001
# auc 0.7708541026887026 SE 0.6073903002309469 SP 0.7830802603036876
# auc 0.7390575368552313 SE 0.6424815983175605 SP 0.7331256490134995
# 0.7390575368552313(0.72-0.76)&0.6540483701366983(0.62-0.68)&0.7082035306334372(0.68-0.74)

#Final Results


# Different Feature Types

'''0.001
auc 0.762913738083191 SE 0.6374133949191686 SP 0.7678958785249458
auc 0.745672424392316 SE 0.6593059936908517 SP 0.7092419522326064
0.7457(0.7241-0.768)&0.6562(0.6271-0.6856)&0.7124(0.6832-0.7405)
(6648, 1200) (1914, 1200) (894, 1200)
(6648, 234) (1914, 234) (894, 234)
0.001
auc 0.7576510547910206 SE 0.6351039260969977 SP 0.7657266811279827
auc 0.741322737283703 SE 0.647739221871714 SP 0.6957424714434061
0.7413(0.7194-0.7639)&0.6446(0.6134-0.6749)&0.6978(0.6703-0.7262)
(6648, 12408) (1914, 12408) (894, 12408)
(6648, 1025) (1914, 1025) (894, 1025)
0.001
auc 0.7683717994319007 SE 0.6558891454965358 SP 0.7462039045553145
auc 0.7572724999535931 SE 0.6698212407991588 SP 0.7133956386292835
0.7573(0.7366-0.7811)&0.6572(0.6263-0.6881)&0.7279(0.7007-0.7558)
(6648, 12300) (1914, 12300) (894, 12300)
(6648, 1010) (1914, 1010) (894, 1010)
0.001
auc 0.7663002910632073 SE 0.6558891454965358 SP 0.7505422993492408
auc 0.7497868014540087 SE 0.668769716088328 SP 0.7185877466251298
0.7498(0.7286-0.7729)&0.6519(0.6223-0.6818)&0.73(0.7036-0.7564)
(6648, 4308) (1914, 4308) (894, 4308)
(6648, 921) (1914, 921) (894, 921)
0.001
auc 0.777111210191721 SE 0.6651270207852193 SP 0.7765726681127982
auc 0.7170874403398947 SE 0.6445846477392219 SP 0.6635514018691588
0.7171(0.6955-0.7373)&0.632(0.6023-0.6606)&0.6739(0.6447-0.705)
(6648, 4200) (1914, 4200) (894, 4200)
(6648, 898) (1914, 898) (894, 898)
0.001
auc 0.7757610977240961 SE 0.6351039260969977 SP 0.7613882863340564
auc 0.713152139137575 SE 0.6603575184016824 SP 0.6573208722741433
0.7132(0.6908-0.7341)&0.6446(0.6115-0.6766)&0.6802(0.6516-0.7107)
(6648, 1527) (1914, 1527) (894, 1527)
(6648, 379) (1914, 379) (894, 379)
0.001
auc 0.68425653639793 SE 0.5981524249422633 SP 0.6832971800433839
auc 0.6795770533940881 SE 0.6151419558359621 SP 0.6687435098650052
0.6796(0.6556-0.7028)&0.6025(0.571-0.6333)&0.6812(0.653-0.7121)
(6648, 1419) (1914, 1419) (894, 1419)
(6648, 347) (1914, 347) (894, 347)
0.001
auc 0.6840586534945119 SE 0.5842956120092379 SP 0.6963123644251626
auc 0.6684923668914943 SE 0.6035751840168244 SP 0.660436137071651
0.6685(0.644-0.6923)&0.5878(0.5544-0.6188)&0.6781(0.6497-0.7055)
0.004349687108612943 0.011566771819137789 0.014537902388369717
0.00748569849958447 0.00525762355415349 -0.0020768431983385627
0.003935301202319663 -0.012618296529968487 -0.006230529595015577
0.011084686502593866 0.014721345951629883 0.0031152647975077885'''

# cough

'''(6648, 436) (1914, 436) (894, 436)
(6648, 92) (1914, 92) (894, 92)
0.001
auc 0.7027974129941437 SE 0.605080831408776 SP 0.6811279826464208
auc 0.732550204026368 SE 0.6529968454258676 SP 0.7019730010384216
0.7326(0.7092-0.7546)&0.6519(0.62-0.6837)&0.7072(0.6789-0.737)
(6648, 400) (1914, 400) (894, 400)
(6648, 82) (1914, 82) (894, 82)
0.001
auc 0.7035789252203012 SE 0.6073903002309469 SP 0.7006507592190889
auc 0.7315974986159838 SE 0.650893796004206 SP 0.7030114226375909
0.7316(0.7082-0.7535)&0.6456(0.6167-0.6743)&0.7082(0.6787-0.7362)
(6648, 4136) (1914, 4136) (894, 4136)
(6648, 452) (1914, 452) (894, 452)
0.001
auc 0.7445632298497593 SE 0.6535796766743649 SP 0.7245119305856833
auc 0.7293497690030606 SE 0.6498422712933754 SP 0.6905503634475597
0.7293(0.7072-0.7507)&0.6414(0.6112-0.6715)&0.6978(0.6694-0.7269)
(6648, 4100) (1914, 4100) (894, 4100)
(6648, 444) (1914, 444) (894, 444)
0.001
auc 0.7473962116695806 SE 0.6397228637413395 SP 0.7245119305856833
auc 0.7296959095361172 SE 0.6424815983175605 SP 0.6936656282450675
0.7297(0.7088-0.7518)&0.6372(0.6059-0.6687)&0.6989(0.6711-0.7279)
(6648, 1436) (1914, 1436) (894, 1436)
(6648, 378) (1914, 378) (894, 378)
0.001
auc 0.7546277046084173 SE 0.6166281755196305 SP 0.7657266811279827
auc 0.7054038324417757 SE 0.6319663512092534 SP 0.6770508826583593
0.7054(0.6832-0.727)&0.6215(0.591-0.6515)&0.6812(0.6508-0.7115)
(6648, 1400) (1914, 1400) (894, 1400)
(6648, 368) (1914, 368) (894, 368)
0.001
auc 0.7528016712338375 SE 0.6304849884526559 SP 0.754880694143167
auc 0.7035945111065252 SE 0.6340694006309149 SP 0.6666666666666666
0.7036(0.683-0.7255)&0.6246(0.5943-0.6542)&0.6729(0.6448-0.7045)
(6648, 509) (1914, 509) (894, 509)
(6648, 135) (1914, 135) (894, 135)
0.001
auc 0.6427161557613983 SE 0.5565819861431871 SP 0.6377440347071583
auc 0.6487492533956168 SE 0.6046267087276551 SP 0.6251298026998962
0.6487(0.6239-0.6725)&0.5752(0.5413-0.6076)&0.6552(0.6254-0.6853)
(6648, 473) (1914, 473) (894, 473)
(6648, 124) (1914, 124) (894, 124)
0.001
auc 0.6448552949958168 SE 0.5796766743648961 SP 0.6507592190889371
auc 0.6291852157591123 SE 0.5709779179810726 SP 0.616822429906542
0.6292(0.6041-0.6533)&0.5279(0.4931-0.5581)&0.6501(0.6179-0.6807)
0.0009527054103841692 0.006309148264984299 -0.0010384215991693369
-0.00034614053305659365 0.004206098843322792 -0.0010384215991693369
0.00180932133525058 -0.003154574132492094 0.00830737279335414
0.019564037636504494 0.04731861198738163 0.005192107995846351'''

# breath

'''0.001
auc 0.616442816850606 SE 0.4341801385681293 SP 0.720173535791757
auc 0.5963728403069185 SE 0.4479495268138801 SP 0.6728971962616822
0.5964(0.5701-0.6217)&0.489(0.4594-0.5228)&0.6521(0.6196-0.6829)
(6648, 400) (1914, 400) (894, 400)
(6648, 85) (1914, 85) (894, 85)
0.001
auc 0.6181611418094013 SE 0.4295612009237875 SP 0.7288503253796096
auc 0.5973648550522869 SE 0.4395373291272345 SP 0.67601246105919
0.5974(0.572-0.6221)&0.4837(0.4507-0.5165)&0.6397(0.6067-0.6691)
(6648, 4136) (1914, 4136) (894, 4136)
(6648, 381) (1914, 381) (894, 381)
0.001
auc 0.6784427867924434 SE 0.5265588914549654 SP 0.7288503253796096
auc 0.6347775146236185 SE 0.5541535226077813 SP 0.656282450674974
0.6348(0.6103-0.6579)&0.5268(0.4952-0.559)&0.675(0.6456-0.7044)
(6648, 4100) (1914, 4100) (894, 4100)
(6648, 373) (1914, 373) (894, 373)
0.001
auc 0.6747556521869817 SE 0.5427251732101617 SP 0.7245119305856833
auc 0.6341272727074196 SE 0.5604626708727655 SP 0.6407061266874351
0.6341(0.6101-0.6574)&0.53(0.4984-0.5616)&0.6625(0.6335-0.6921)
(6648, 1436) (1914, 1436) (894, 1436)
(6648, 308) (1914, 308) (894, 308)
0.001
auc 0.6559592812091396 SE 0.5242494226327945 SP 0.6702819956616052
auc 0.6251702039608523 SE 0.555205047318612 SP 0.6417445482866043
0.6252(0.6015-0.6489)&0.5363(0.5042-0.5664)&0.6604(0.6298-0.6916)
(6648, 1400) (1914, 1400) (894, 1400)
(6648, 298) (1914, 298) (894, 298)
0.001
auc 0.6556887577462389 SE 0.5265588914549654 SP 0.6984815618221258
auc 0.621217431942984 SE 0.5520504731861199 SP 0.6375908618899273
0.6212(0.5978-0.6448)&0.5237(0.4923-0.5543)&0.6563(0.6256-0.6875)
(6648, 509) (1914, 509) (894, 509)
(6648, 132) (1914, 132) (894, 132)
0.001
auc 0.5291113304243712 SE 0.43648960739030024 SP 0.5986984815618221
auc 0.5578829957644191 SE 0.4773922187171398 SP 0.6116303219106958
0.5579(0.5296-0.5832)&0.4006(0.3668-0.4303)&0.6584(0.6289-0.686)
(6648, 473) (1914, 473) (894, 473)
(6648, 120) (1914, 120) (894, 120)
0.001
Modalityauc 0.5305390931452361 SE 0.4295612009237875 SP 0.613882863340564
auc 0.5456496031395055 SE 0.45846477392218715 SP 0.6105919003115264
0.5456(0.5184-0.5709)&0.3996(0.3676-0.4273)&0.6656(0.638-0.6936)
-0.0009920147453683636 0.005257623554153545 0.012461059190031154
0.0006502419161988904 -0.003154574132492094 0.012461059190031154
0.003952772017868367 0.012618296529968487 0.004153686396677014
0.01223339262491363 0.001051524710830698 -0.007268951194184803'''

# voice

'''(myenv) (base) ojg30@phy-w1-pc245:~/bigstore/covid19-sounds-neurips/Respiratory_prediction/Opensmile$ python 2_classifcation.py 
(6648, 436) (1914, 436) (894, 436)
(6648, 91) (1914, 91) (894, 91)
0.001
auc 0.6325089047306538 SE 0.5057736720554272 SP 0.6746203904555315
auc 0.6212048747943084 SE 0.5226077812828601 SP 0.660436137071651
0.6212(0.5965-0.6478)&0.53(0.4959-0.5615)&0.6521(0.6192-0.6807)
(6648, 400) (1914, 400) (894, 400)
(6648, 80) (1914, 80) (894, 80)
0.001
auc 0.6258585362676778 SE 0.5011547344110855 SP 0.6507592190889371
auc 0.6096288216044106 SE 0.5057833859095688 SP 0.6303219106957425
0.6096(0.5833-0.6371)&0.511(0.4794-0.5432)&0.6303(0.5977-0.6603)
(6648, 4136) (1914, 4136) (894, 4136)
(6648, 452) (1914, 452) (894, 452)
0.001
auc 0.6479437711972666 SE 0.5635103926096998 SP 0.648590021691974
auc 0.6710212674421526 SE 0.5720294426919033 SP 0.6666666666666666
0.671(0.6475-0.6934)&0.5605(0.5304-0.5909)&0.6791(0.6512-0.7086)
(6648, 4100) (1914, 4100) (894, 4100)
(6648, 444) (1914, 444) (894, 444)
0.001
auc 0.6467715028580303 SE 0.5612009237875288 SP 0.6507592190889371
auc 0.6636698758370978 SE 0.5667718191377498 SP 0.6542056074766355
0.6637(0.6392-0.6863)&0.5594(0.5287-0.5899)&0.6625(0.6322-0.6929)
(6648, 1436) (1914, 1436) (894, 1436)
(6648, 354) (1914, 354) (894, 354)
0.001
auc 0.6743699057676604 SE 0.5519630484988453 SP 0.6832971800433839
auc 0.6318014703875137 SE 0.5488958990536278 SP 0.6272066458982347
0.6318(0.6071-0.6547)&0.5321(0.5005-0.5628)&0.6376(0.6081-0.6678)
(6648, 1400) (1914, 1400) (894, 1400)
(6648, 343) (1914, 343) (894, 343)
0.001
auc 0.6734681608913247 SE 0.5427251732101617 SP 0.7006507592190889
auc 0.627578992654614 SE 0.5509989484752892 SP 0.616822429906542
0.6276(0.6027-0.6497)&0.5363(0.5054-0.5668)&0.6262(0.5958-0.6575)
(6648, 509) (1914, 509) (894, 509)
(6648, 133) (1914, 133) (894, 133)
0.001
auc 0.6373883464503814 SE 0.5057736720554272 SP 0.6984815618221258
auc 0.62395270650231 SE 0.480546792849632 SP 0.7061266874350987
0.624(0.5997-0.6496)&0.489(0.4567-0.5187)&0.6999(0.6719-0.7298)
(6648, 473) (1914, 473) (894, 473)
(6648, 121) (1914, 121) (894, 121)
0.001
auc 0.6390315260028154 SE 0.49884526558891457 SP 0.6984815618221258
auc 0.6176102544951863 SE 0.46898002103049424 SP 0.6915887850467289
0.6176(0.5921-0.6428)&0.4711(0.4376-0.5038)&0.6906(0.6612-0.7203)
0.01157605318989785 0.018927444794952675 0.02180685358255452
0.0073513916050548245 0.001051524710830698 0.01661474558670817
0.004222477732899632 -0.004206098843322792 0.011422637590861928
0.0063424520071238 0.017875920084121977 0.009345794392523366'''

#THE BENCHMARK

'''auc 0.7864818423649762 SE 0.6558891454965358 SP 0.7678958785249458
auc 0.7495274690357092 SE 0.6698212407991588 SP 0.7009345794392523
0.7495(0.7289-0.7697)&0.653(0.6215-0.6839)&0.7207(0.6919-0.7492)'''


# 384

'''0.001
auc 0.7993918231778492 SE 0.6581986143187067 SP 0.7852494577006508
auc 0.7438319831668692 SE 0.6656151419558359 SP 0.6926272066458983
0.7438(0.7231-0.7663)&0.6551(0.6238-0.6868)&0.704(0.676-0.7341)
(6648, 1152) (1914, 1152) (894, 1152)
(6648, 395) (1914, 395) (894, 395)
0.001
auc 0.8026556386608087 SE 0.6697459584295612 SP 0.806941431670282
auc 0.7354874848904743 SE 0.6603575184016824 SP 0.6843198338525441
0.7355(0.7136-0.7567)&0.6551(0.6249-0.6852)&0.6906(0.6606-0.7204)
(6648, 420) (1914, 420) (894, 420)
(6648, 148) (1914, 148) (894, 148)
0.001
auc 0.7651455566521219 SE 0.6420323325635104 SP 0.7722342733188721
auc 0.7111861264253729 SE 0.6256572029442692 SP 0.6780893042575286
0.7112(0.6892-0.7356)&0.6183(0.5868-0.6481)&0.6833(0.6525-0.7124)
(6648, 384) (1914, 384) (894, 384)
(6648, 138) (1914, 138) (894, 138)
0.001
auc 0.7684043624413239 SE 0.651270207852194 SP 0.7722342733188721
auc 0.7080692237389075 SE 0.6088328075709779 SP 0.6770508826583593
0.7081(0.686-0.7328)&0.6036(0.5711-0.6333)&0.6812(0.6516-0.7102)
(6648, 420) (1914, 420) (894, 420)
(6648, 154) (1914, 154) (894, 154)
0.001
auc 0.690516148747827 SE 0.5080831408775982 SP 0.7462039045553145
auc 0.6280266823030467 SE 0.4942166140904311 SP 0.6780893042575286
0.628(0.6029-0.6543)&0.5068(0.4743-0.5372)&0.6708(0.6393-0.7)
(6648, 384) (1914, 384) (894, 384)
(6648, 144) (1914, 144) (894, 144)
0.001
auc 0.6963875098315241 SE 0.5242494226327945 SP 0.7440347071583514
auc 0.6269052743300215 SE 0.5131440588853838 SP 0.6708203530633438
0.6269(0.602-0.6522)&0.5205(0.4871-0.5544)&0.6584(0.6258-0.6879)
(6648, 420) (1914, 420) (894, 420)
(6648, 151) (1914, 151) (894, 151)
0.001
auc 0.6600496961620737 SE 0.5219399538106235 SP 0.7049891540130152
auc 0.6333640164531407 SE 0.5331230283911672 SP 0.656282450674974
0.6334(0.6085-0.6568)&0.5331(0.5005-0.5637)&0.6563(0.6253-0.6883)
(6648, 384) (1914, 384) (894, 384)
(6648, 140) (1914, 140) (894, 140)
0.001
auc 0.6550374975577742 SE 0.5219399538106235 SP 0.6941431670281996
auc 0.6309060910906484 SE 0.5320715036803365 SP 0.6500519210799585
0.6309(0.6056-0.6539)&0.5321(0.5-0.5643)&0.6501(0.6215-0.6792)
0.00834449827639483 0.0 0.01349948078920038
0.0031169026864654725 0.014721345951629883 0.0020768431983385627
0.0011214079730251791 -0.013669821240799185 0.012461059190031154
0.0024579253624922304 0.001051524710830698 0.006230529595015577'''

# 988

'''0.001
auc 0.7895327458632454 SE 0.6535796766743649 SP 0.7635574837310195
auc 0.745083330330537 SE 0.6803364879074658 SP 0.6967808930425753
0.7451(0.7234-0.7666)&0.6625(0.6333-0.6913)&0.7082(0.6795-0.738)
(6648, 2964) (1914, 2964) (894, 2964)
(6648, 573) (1914, 573) (894, 573)
0.001
auc 0.792052621823228 SE 0.6581986143187067 SP 0.7722342733188721
auc 0.745308267080725 SE 0.6824395373291272 SP 0.6874350986500519
0.7453(0.7243-0.7668)&0.673(0.644-0.7016)&0.6999(0.6722-0.7306)
(6648, 1024) (1914, 1024) (894, 1024)
(6648, 227) (1914, 227) (894, 227)
0.001
auc 0.7590011672586454 SE 0.625866050808314 SP 0.7809110629067245
auc 0.7233387165283742 SE 0.6403785488958991 SP 0.6895119418483905
0.7233(0.702-0.7459)&0.6372(0.6075-0.6646)&0.6968(0.6684-0.7237)
(6648, 988) (1914, 988) (894, 988)
(6648, 217) (1914, 217) (894, 217)
0.001
auc 0.7640835015755487 SE 0.6374133949191686 SP 0.7722342733188721
auc 0.72252031801252 SE 0.6403785488958991 SP 0.6998961578400831
0.7225(0.7006-0.7456)&0.6362(0.6044-0.6656)&0.704(0.6761-0.731)
(6648, 1024) (1914, 1024) (894, 1024)
(6648, 220) (1914, 220) (894, 220)
0.001
auc 0.6778766913978549 SE 0.5404157043879908 SP 0.7158351409978309
auc 0.6455455425943943 SE 0.5657202944269191 SP 0.6593977154724818
0.6455(0.6217-0.6703)&0.5499(0.5185-0.5814)&0.6677(0.6375-0.6959)
(6648, 988) (1914, 988) (894, 988)
(6648, 211) (1914, 211) (894, 211)
0.001
auc 0.6812281765215692 SE 0.558891454965358 SP 0.7114967462039046
auc 0.6444983855874507 SE 0.562565720294427 SP 0.6593977154724818
0.6445(0.6209-0.6689)&0.5542(0.5237-0.5851)&0.6667(0.635-0.6954)
(6648, 1024) (1914, 1024) (894, 1024)
(6648, 214) (1914, 214) (894, 214)
0.001
auc 0.6675492077169323 SE 0.5450346420323325 SP 0.6919739696312365
auc 0.6527173123770902 SE 0.5541535226077813 SP 0.6510903426791277
0.6527(0.6277-0.6758)&0.551(0.5179-0.5833)&0.6604(0.6299-0.6901)
(6648, 988) (1914, 988) (894, 988)
(6648, 204) (1914, 204) (894, 204)
0.001
auc 0.664991759053769 SE 0.5496535796766744 SP 0.6811279826464208
auc 0.6499962328553973 SE 0.5583596214511041 SP 0.6375908618899273
0.65(0.6248-0.6737)&0.551(0.5202-0.5836)&0.648(0.6177-0.6783)
-0.0002249367501879762 -0.01051524710830709 0.00830737279335414
0.0008183985158541907 0.001051524710830698 -0.007268951194184803
0.0010471570069436886 -0.004206098843322792 0.0010384215991693369
0.0027210795216928707 0.0 0.012461059190031154'''